{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7aafcb2-fa18-4b50-8374-0ee02625aa6f",
   "metadata": {},
   "source": [
    "# 6.1 Reading and Writing Data in Text Format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300ba7b-9526-4824-974b-78fe859e45c9",
   "metadata": {},
   "source": [
    "Parsing functions in pandas:\n",
    "- `read_csv`\n",
    "- `read_fwf`\n",
    "- `read_clipboard`\n",
    "- `read_excel`\n",
    "- `read_hdf`\n",
    "- `read_html`\n",
    "- `read_json`\n",
    "- `read_msgpack`\n",
    "- `read_pickle`\n",
    "- `read_sas`\n",
    "- `read_sql`\n",
    "- `read_stata`\n",
    "- `read_feather`\n",
    "\n",
    "With optinal arguments: \n",
    "- Indexing: Can treat one or more columns as the returned DF, and whether to get column names from the file, the user, or not at all\n",
    "- Type Inference and Data Conversion: Includes the **user-defined value conversions** and custom list of missing value markers.\n",
    "- Datetime Parsing: Includes **combining capability**, including combining date and time info spread over multiple columns into a single column in the result.\n",
    "- Iterating: Iterating over chunks of very large files.\n",
    "- Unclean Data Issues: Skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas.\n",
    "\n",
    "Some of these functions perform type inference because the column data types are not part of the data format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0d415b-94fc-43c4-b3ef-43e0d1c7000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>2</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   2 message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read examples/ex1.csv\n",
    "import pandas as pd \n",
    "df = pd.read_csv('examples/ex1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582fc0f-140f-4721-a9f5-aac66f302384",
   "metadata": {},
   "source": [
    "Notice the file has a header row. If the file you are working with does not have one, pass `header=None` **or** assign the names to the columns yourself by passing the `names` argument. \n",
    "- `df = pd.read_csv('examples/ex1.csv, header=None)`\n",
    "- `df = pd.read_csv('examples/ex1.csv, names=['col1','col2', ...])`\n",
    "\n",
    "You can indicate what column you would like to be the index column:\n",
    "- `index_col='col6`\n",
    "\n",
    "Furthermore you can create a hierarchical index (multiple index values) by passing a list of columns to the `index_col` argument. \n",
    "\n",
    "In cases where the data does not have a fixed delimiter, you can pass `sep` argument, and use a **regular expression** to choose the delimeter. `read_csv` can infer which column to be the DF's index. I*t does this by noticing that there is one fewer column name in the data u are passing. \n",
    "\n",
    "Pass a list of indeces to the `skiprows` argument to skip those rows when loading in the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0558acb-7e64-4b05-9058-09d7aa1aed2f",
   "metadata": {},
   "source": [
    " Handling missing values is an important and frequently nuanced part of the file parsing process. Missing data is usually either not present (empty string) or marked by some **sentinel** value. By default, pandas uses a set of commonly occurring sentinels such as `NA` and `NULL`. \n",
    " - Use `pd.isnull(data_frame)` to return a boolean DF indicating missing values. Furthermore you can use this as a mask :)\n",
    "- Pass a list, dict, or a set of strings to the `na_values` argument to assign missing values.\n",
    "- You can assign different `NA` sentinels to each column, just pass a dict to the `na_values` argument with the column name as the key and the sentinel as the value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592d3c6-6633-4077-b696-3be43e93a5e1",
   "metadata": {},
   "source": [
    "Common `read_csv` function arguments:\n",
    "- `path`\n",
    "- `sep` or `delimeter`\n",
    "- `header` a row number to use as column names\n",
    "- `index_col`\n",
    "- `names`\n",
    "- `skiprows`\n",
    "- `na_values`\n",
    "- `comment`\n",
    "- `parse_dates`\n",
    "- `keep_date_col`\n",
    "- `converters`\n",
    "- `dayfirst`\n",
    "- `date_parser` a function to use to parse data\n",
    "- `nrows`\n",
    "- `iterator`\n",
    "- `chunksize`\n",
    "- `skip_footer`\n",
    "- `verbose`\n",
    "- `encoding`\n",
    "- `squeeze` Returns a series if the parsed data only contains one column.\n",
    "- `thousands`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d81cdf-bc5f-45eb-ba0f-b7d4d1f5d706",
   "metadata": {},
   "source": [
    "## Reading Text Files in Pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf581b50-76f9-4dc6-a082-48dd7ff567b9",
   "metadata": {},
   "source": [
    "Use the `nrows` argument with `pd.read_csv()` to limit the number of rows to load in. Alternatively, iterate over the file according to chunk size using `chunksize` argument \n",
    "- Create a `TextFileReader` chunk object: `chunker = pd.read_csv('path', cunksize=1000)`\n",
    "- Now use this object to iterate over the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5344c4f-7d45-40c1-be2a-76b9e205703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the counts in the 'key' column of our data. \n",
    "\n",
    "# total = pd.Series([])\n",
    "# for piece in chunker: \n",
    "#     total.add(piece['key'].value_counts(), fill_value = 0)\n",
    "# total = sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236e3e1-14a5-47e9-b481-78caf3f5688d",
   "metadata": {},
   "source": [
    "This code returns a series `total` with the index as the column specified `key` and the values are the value counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce4cc8-db26-43e8-a78e-19f082fa0962",
   "metadata": {},
   "source": [
    "## Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f0b42-fc05-4f25-bfbb-29ac135bee06",
   "metadata": {},
   "source": [
    "Use the `to_csv` method. \n",
    "- `sep` can be used here for delimiter.\n",
    "- By default, missing values appear as empty strings in the output. Pass `na_rep` to change this.\n",
    "- Both the rown and column labels are written by default. This can be disabled with `index=False`, `header=False`.\n",
    "- Write only a subset of the columns by passing a list of column names to `columns` argument\n",
    "- Series also have a `to_csv` method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772ad7d-b37c-4c5f-9778-ce466b2bc108",
   "metadata": {},
   "source": [
    "## Working with Delimited Formats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9df82f-1439-44a6-9492-aedebec1f3fa",
   "metadata": {},
   "source": [
    "For any file with a single-character delimiter, you can use Pythons built-in csv module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0770ed-c251-4437-bf1f-b1e8328c37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "f = open('examples/ex7.csv')\n",
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec78806-d8fa-497e-8a12-3a334949ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "for line in reader:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff9389-ac93-4a68-9f66-7cae8e63b3cd",
   "metadata": {},
   "source": [
    "Now lets put the data in the form that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17effb32-6466-4299-bcae-84958f685543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('examples/ex7.csv') as f:\n",
    "    lines=list(csv.reader(f))\n",
    "\n",
    "# split the lines into the header line and the data lines:\n",
    "header, values = lines[0], lines[1:]\n",
    "\n",
    "# create a dict of data columns using dict comprehension and the expression zip(*values), which transpose rows to columns. \n",
    "data_dict = {h:v for h, v in zip(header, zip(*values))}\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b961f2-3b8d-4073-adbb-357b30d4dd0d",
   "metadata": {},
   "source": [
    "Since CSV files come in many different flavors, we can define a new format with a different delimiter, string quoting convention, or line terminator. Define a simple subclass of `csv.Dialect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3265e2-14f1-4e2a-80a0-fc0a9e2e930d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "\n",
    "reader = csv.reader(f, dialect = my_dialect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6caf8e-8e5c-405f-a02e-333330d803da",
   "metadata": {},
   "source": [
    "If you dont need to go this far with it, you can simply pass one of these as an argument to `csv.reader`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e384768-64f6-4474-9505-e141b4b67bff",
   "metadata": {},
   "source": [
    "CSV Dialect Options:\n",
    "- `delimiter`\n",
    "- `lineterminator`\n",
    "- `quotechar`\n",
    "- `quoting`\n",
    "- `skipinitialspace`\n",
    "- `doublequote`\n",
    "- `escapechar`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0991443-22fb-42e7-85e6-05a0522b9378",
   "metadata": {},
   "source": [
    "Note: For files with more complicated or fixed multicharacter delimiters, you will not be able to use the `csv` module. In those cases, you will have to do the line splitting and other cleanup using string's `split` method or the regular expression method `re.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22ad63-3452-4a0e-8d5b-a8917822b263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6fa47-f893-4dcc-8420-3ddf922dbbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916526ea-d80c-4653-8209-dee952934a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebba80c-8792-4b93-bc48-d39c81a3f987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded376c-1796-46da-af7a-4c45d8e3867b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7f42c-72eb-4837-9d2e-7128b903d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa4d69-99d5-4f16-8f4a-d679f5291948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1943092-c474-4003-a2d4-c3f02e7101d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6b786-65b3-47ee-8eed-8bfa1d6117d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3f88a-e81a-4ed5-b319-9e718dfcd0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bb6a5-6847-43bc-9e47-689c747791ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0d524-70a1-4ec9-aebb-d5dbc9811774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cda99-4956-4d57-aa41-4a85a4e4676d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d34d6b-ba35-4da2-9a46-54c659dcdced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b6867-9150-4a29-a3d0-4ad562947297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01ee7b-b61f-43df-b430-cacb4b6f36e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381e18c-8a8f-44d0-be81-e576348d9742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe6690-b6f4-4203-a421-f1ebefc32b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b0bf3-397b-4937-adb2-67a9478059b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc2796-a28e-4ca9-b037-3f3618f2f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e334e33-93fd-45e7-ab7f-6b68680ee012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e0690-0625-4cea-9da7-a50e760468c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5a9f0-43f9-492f-bbed-b682e2c1b27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2707f8-2874-451f-959f-b33edbd2d558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
